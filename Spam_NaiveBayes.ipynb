{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spam_NaiveBayes.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EGStED6wiLT"
      },
      "source": [
        "# SPAM OR NO SPAM PREDICTION- NaiveBayes Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sigKjDTAwzuN"
      },
      "source": [
        "## Defining the question\n",
        "\n",
        "Given the data, we are to predict whether an email is spam or not by building a Naive Bayes Model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfTrKuEhxCPT"
      },
      "source": [
        "## Metric for success\n",
        "\n",
        "Our analysis will be considered successful if we are able to develop a Naive Bayes model that can accurately predict whether or not an email is spam."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RPIJGDCxFa4"
      },
      "source": [
        "## Understanding the context\n",
        "The spam dataset's final column indicates whether the e-mail was considered spam (1) or not (0). The majority of the attributes indicate whether a specific word or character appeared frequently in the e-mail."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1E-oXgVxLKC"
      },
      "source": [
        "## Experimental design\n",
        "\n",
        "- Data Preparation\n",
        "- Exploratory Data Analysis\n",
        "- Data Preprocessing\n",
        "- Building our models: Gaussian,Multinomial\n",
        "- Challenging the solutions\n",
        "- Conclusion and Recommendations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxOMGAj2xQie"
      },
      "source": [
        "## Reading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cV6Utyrdw4bt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19f71c48-fc06-4f62-abcd-f1109bac1b4c"
      },
      "source": [
        "# Import Libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
        "from pandas_profiling import ProfileReport\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
        "\n",
        "# Set global parameters\n",
        "%matplotlib inline\n",
        "sns.set()\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVuTNNlB_S62",
        "outputId": "1cb257c7-bdb6-40f5-d8f6-2eeaace66171"
      },
      "source": [
        "# Loading our datasets\n",
        "with open('/content/spambase (1).names') as file:\n",
        "  names = file.read()\n",
        "  print(names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| SPAM E-MAIL DATABASE ATTRIBUTES (in .names format)\n",
            "|\n",
            "| 48 continuous real [0,100] attributes of type word_freq_WORD \n",
            "| = percentage of words in the e-mail that match WORD,\n",
            "| i.e. 100 * (number of times the WORD appears in the e-mail) / \n",
            "| total number of words in e-mail.  A \"word\" in this case is any \n",
            "| string of alphanumeric characters bounded by non-alphanumeric \n",
            "| characters or end-of-string.\n",
            "|\n",
            "| 6 continuous real [0,100] attributes of type char_freq_CHAR\n",
            "| = percentage of characters in the e-mail that match CHAR,\n",
            "| i.e. 100 * (number of CHAR occurences) / total characters in e-mail\n",
            "|\n",
            "| 1 continuous real [1,...] attribute of type capital_run_length_average\n",
            "| = average length of uninterrupted sequences of capital letters\n",
            "|\n",
            "| 1 continuous integer [1,...] attribute of type capital_run_length_longest\n",
            "| = length of longest uninterrupted sequence of capital letters\n",
            "|\n",
            "| 1 continuous integer [1,...] attribute of type capital_run_length_total\n",
            "| = sum of length of uninterrupted sequences of capital letters\n",
            "| = total number of capital letters in the e-mail\n",
            "|\n",
            "| 1 nominal {0,1} class attribute of type spam\n",
            "| = denotes whether the e-mail was considered spam (1) or not (0), \n",
            "| i.e. unsolicited commercial e-mail.  \n",
            "|\n",
            "| For more information, see file 'spambase.DOCUMENTATION' at the\n",
            "| UCI Machine Learning Repository: http://www.ics.uci.edu/~mlearn/MLRepository.html\n",
            "\n",
            "\n",
            "1, 0.    | spam, non-spam classes\n",
            "\n",
            "word_freq_make:         continuous.\n",
            "word_freq_address:      continuous.\n",
            "word_freq_all:          continuous.\n",
            "word_freq_3d:           continuous.\n",
            "word_freq_our:          continuous.\n",
            "word_freq_over:         continuous.\n",
            "word_freq_remove:       continuous.\n",
            "word_freq_internet:     continuous.\n",
            "word_freq_order:        continuous.\n",
            "word_freq_mail:         continuous.\n",
            "word_freq_receive:      continuous.\n",
            "word_freq_will:         continuous.\n",
            "word_freq_people:       continuous.\n",
            "word_freq_report:       continuous.\n",
            "word_freq_addresses:    continuous.\n",
            "word_freq_free:         continuous.\n",
            "word_freq_business:     continuous.\n",
            "word_freq_email:        continuous.\n",
            "word_freq_you:          continuous.\n",
            "word_freq_credit:       continuous.\n",
            "word_freq_your:         continuous.\n",
            "word_freq_font:         continuous.\n",
            "word_freq_000:          continuous.\n",
            "word_freq_money:        continuous.\n",
            "word_freq_hp:           continuous.\n",
            "word_freq_hpl:          continuous.\n",
            "word_freq_george:       continuous.\n",
            "word_freq_650:          continuous.\n",
            "word_freq_lab:          continuous.\n",
            "word_freq_labs:         continuous.\n",
            "word_freq_telnet:       continuous.\n",
            "word_freq_857:          continuous.\n",
            "word_freq_data:         continuous.\n",
            "word_freq_415:          continuous.\n",
            "word_freq_85:           continuous.\n",
            "word_freq_technology:   continuous.\n",
            "word_freq_1999:         continuous.\n",
            "word_freq_parts:        continuous.\n",
            "word_freq_pm:           continuous.\n",
            "word_freq_direct:       continuous.\n",
            "word_freq_cs:           continuous.\n",
            "word_freq_meeting:      continuous.\n",
            "word_freq_original:     continuous.\n",
            "word_freq_project:      continuous.\n",
            "word_freq_re:           continuous.\n",
            "word_freq_edu:          continuous.\n",
            "word_freq_table:        continuous.\n",
            "word_freq_conference:   continuous.\n",
            "char_freq_;:            continuous.\n",
            "char_freq_(:            continuous.\n",
            "char_freq_[:            continuous.\n",
            "char_freq_!:            continuous.\n",
            "char_freq_$:            continuous.\n",
            "char_freq_#:            continuous.\n",
            "capital_run_length_average: continuous.\n",
            "capital_run_length_longest: continuous.\n",
            "capital_run_length_total:   continuous.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBzeI_hZAa4u"
      },
      "source": [
        "# Lets get our column names and enter them in a list from the data above\n",
        "columns = ['word_freq_make',\n",
        "          'word_freq_address',      \n",
        "          'word_freq_all',          \n",
        "          'word_freq_3d',          \n",
        "          'word_freq_our',          \n",
        "          'word_freq_over',         \n",
        "          'word_freq_remove',       \n",
        "          'word_freq_internet',     \n",
        "          'word_freq_order',        \n",
        "          'word_freq_mail',         \n",
        "          'word_freq_receive',      \n",
        "          'word_freq_will',         \n",
        "          'word_freq_people',       \n",
        "          'word_freq_report',       \n",
        "          'word_freq_addresses',    \n",
        "          'word_freq_free',         \n",
        "          'word_freq_business',     \n",
        "          'word_freq_email',        \n",
        "          'word_freq_you',          \n",
        "          'word_freq_credit',       \n",
        "          'word_freq_your',         \n",
        "          'word_freq_font',         \n",
        "          'word_freq_000',          \n",
        "          'word_freq_money',        \n",
        "          'word_freq_hp',           \n",
        "          'word_freq_hpl',          \n",
        "          'word_freq_george',       \n",
        "          'word_freq_650',          \n",
        "          'word_freq_lab',          \n",
        "          'word_freq_labs',         \n",
        "          'word_freq_telnet',       \n",
        "          'word_freq_857',          \n",
        "          'word_freq_data',         \n",
        "          'word_freq_415',          \n",
        "          'word_freq_85',           \n",
        "          'word_freq_technology',   \n",
        "          'word_freq_1999',         \n",
        "          'word_freq_parts',        \n",
        "          'word_freq_pm',           \n",
        "          'word_freq_direct',       \n",
        "          'word_freq_cs',           \n",
        "          'word_freq_meeting',      \n",
        "          'word_freq_original',     \n",
        "          'word_freq_project',      \n",
        "          'word_freq_re',           \n",
        "          'word_freq_edu',          \n",
        "          'word_freq_table',        \n",
        "          'word_freq_conference',   \n",
        "          'char_freq_;',            \n",
        "          'char_freq_(',            \n",
        "          'char_freq_[',            \n",
        "          'char_freq_!',            \n",
        "          'char_freq_$',            \n",
        "          'char_freq_#',            \n",
        "          'capital_run_length_average', \n",
        "          'capital_run_length_longest', \n",
        "          'capital_run_length_total',\n",
        "          'spam']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qv-8PeRXDAOZ"
      },
      "source": [
        "# Loading email data\n",
        "email = pd.read_csv('/content/spambase (1).data', names=columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muyB9j3vD9fN"
      },
      "source": [
        "## Checking the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "cX03MAutDZkn",
        "outputId": "390e4cbc-9f0b-432d-b6cd-c1065348de3e"
      },
      "source": [
        "# Preview the top of our data\n",
        "email.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word_freq_make</th>\n",
              "      <th>word_freq_address</th>\n",
              "      <th>word_freq_all</th>\n",
              "      <th>word_freq_3d</th>\n",
              "      <th>word_freq_our</th>\n",
              "      <th>word_freq_over</th>\n",
              "      <th>word_freq_remove</th>\n",
              "      <th>word_freq_internet</th>\n",
              "      <th>word_freq_order</th>\n",
              "      <th>word_freq_mail</th>\n",
              "      <th>word_freq_receive</th>\n",
              "      <th>word_freq_will</th>\n",
              "      <th>word_freq_people</th>\n",
              "      <th>word_freq_report</th>\n",
              "      <th>word_freq_addresses</th>\n",
              "      <th>word_freq_free</th>\n",
              "      <th>word_freq_business</th>\n",
              "      <th>word_freq_email</th>\n",
              "      <th>word_freq_you</th>\n",
              "      <th>word_freq_credit</th>\n",
              "      <th>word_freq_your</th>\n",
              "      <th>word_freq_font</th>\n",
              "      <th>word_freq_000</th>\n",
              "      <th>word_freq_money</th>\n",
              "      <th>word_freq_hp</th>\n",
              "      <th>word_freq_hpl</th>\n",
              "      <th>word_freq_george</th>\n",
              "      <th>word_freq_650</th>\n",
              "      <th>word_freq_lab</th>\n",
              "      <th>word_freq_labs</th>\n",
              "      <th>word_freq_telnet</th>\n",
              "      <th>word_freq_857</th>\n",
              "      <th>word_freq_data</th>\n",
              "      <th>word_freq_415</th>\n",
              "      <th>word_freq_85</th>\n",
              "      <th>word_freq_technology</th>\n",
              "      <th>word_freq_1999</th>\n",
              "      <th>word_freq_parts</th>\n",
              "      <th>word_freq_pm</th>\n",
              "      <th>word_freq_direct</th>\n",
              "      <th>word_freq_cs</th>\n",
              "      <th>word_freq_meeting</th>\n",
              "      <th>word_freq_original</th>\n",
              "      <th>word_freq_project</th>\n",
              "      <th>word_freq_re</th>\n",
              "      <th>word_freq_edu</th>\n",
              "      <th>word_freq_table</th>\n",
              "      <th>word_freq_conference</th>\n",
              "      <th>char_freq_;</th>\n",
              "      <th>char_freq_(</th>\n",
              "      <th>char_freq_[</th>\n",
              "      <th>char_freq_!</th>\n",
              "      <th>char_freq_$</th>\n",
              "      <th>char_freq_#</th>\n",
              "      <th>capital_run_length_average</th>\n",
              "      <th>capital_run_length_longest</th>\n",
              "      <th>capital_run_length_total</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.29</td>\n",
              "      <td>1.93</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.778</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.756</td>\n",
              "      <td>61</td>\n",
              "      <td>278</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.21</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.28</td>\n",
              "      <td>3.47</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.59</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.132</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.372</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.048</td>\n",
              "      <td>5.114</td>\n",
              "      <td>101</td>\n",
              "      <td>1028</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.23</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.75</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.36</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.16</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.276</td>\n",
              "      <td>0.184</td>\n",
              "      <td>0.010</td>\n",
              "      <td>9.821</td>\n",
              "      <td>485</td>\n",
              "      <td>2259</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.18</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.18</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   word_freq_make  word_freq_address  ...  capital_run_length_total  spam\n",
              "0            0.00               0.64  ...                       278     1\n",
              "1            0.21               0.28  ...                      1028     1\n",
              "2            0.06               0.00  ...                      2259     1\n",
              "3            0.00               0.00  ...                       191     1\n",
              "4            0.00               0.00  ...                       191     1\n",
              "\n",
              "[5 rows x 58 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "GfEFjUPFDjgS",
        "outputId": "27e86a9f-bf9d-427d-9440-e28cfeabca27"
      },
      "source": [
        "# preview the bottom of our data\n",
        "email.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word_freq_make</th>\n",
              "      <th>word_freq_address</th>\n",
              "      <th>word_freq_all</th>\n",
              "      <th>word_freq_3d</th>\n",
              "      <th>word_freq_our</th>\n",
              "      <th>word_freq_over</th>\n",
              "      <th>word_freq_remove</th>\n",
              "      <th>word_freq_internet</th>\n",
              "      <th>word_freq_order</th>\n",
              "      <th>word_freq_mail</th>\n",
              "      <th>word_freq_receive</th>\n",
              "      <th>word_freq_will</th>\n",
              "      <th>word_freq_people</th>\n",
              "      <th>word_freq_report</th>\n",
              "      <th>word_freq_addresses</th>\n",
              "      <th>word_freq_free</th>\n",
              "      <th>word_freq_business</th>\n",
              "      <th>word_freq_email</th>\n",
              "      <th>word_freq_you</th>\n",
              "      <th>word_freq_credit</th>\n",
              "      <th>word_freq_your</th>\n",
              "      <th>word_freq_font</th>\n",
              "      <th>word_freq_000</th>\n",
              "      <th>word_freq_money</th>\n",
              "      <th>word_freq_hp</th>\n",
              "      <th>word_freq_hpl</th>\n",
              "      <th>word_freq_george</th>\n",
              "      <th>word_freq_650</th>\n",
              "      <th>word_freq_lab</th>\n",
              "      <th>word_freq_labs</th>\n",
              "      <th>word_freq_telnet</th>\n",
              "      <th>word_freq_857</th>\n",
              "      <th>word_freq_data</th>\n",
              "      <th>word_freq_415</th>\n",
              "      <th>word_freq_85</th>\n",
              "      <th>word_freq_technology</th>\n",
              "      <th>word_freq_1999</th>\n",
              "      <th>word_freq_parts</th>\n",
              "      <th>word_freq_pm</th>\n",
              "      <th>word_freq_direct</th>\n",
              "      <th>word_freq_cs</th>\n",
              "      <th>word_freq_meeting</th>\n",
              "      <th>word_freq_original</th>\n",
              "      <th>word_freq_project</th>\n",
              "      <th>word_freq_re</th>\n",
              "      <th>word_freq_edu</th>\n",
              "      <th>word_freq_table</th>\n",
              "      <th>word_freq_conference</th>\n",
              "      <th>char_freq_;</th>\n",
              "      <th>char_freq_(</th>\n",
              "      <th>char_freq_[</th>\n",
              "      <th>char_freq_!</th>\n",
              "      <th>char_freq_$</th>\n",
              "      <th>char_freq_#</th>\n",
              "      <th>capital_run_length_average</th>\n",
              "      <th>capital_run_length_longest</th>\n",
              "      <th>capital_run_length_total</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4596</th>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.232</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.142</td>\n",
              "      <td>3</td>\n",
              "      <td>88</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4597</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.353</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.555</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4598</th>\n",
              "      <td>0.30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.102</td>\n",
              "      <td>0.718</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.404</td>\n",
              "      <td>6</td>\n",
              "      <td>118</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4599</th>\n",
              "      <td>0.96</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.93</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.057</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.147</td>\n",
              "      <td>5</td>\n",
              "      <td>78</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4600</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.60</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.97</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.250</td>\n",
              "      <td>5</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      word_freq_make  word_freq_address  ...  capital_run_length_total  spam\n",
              "4596            0.31                0.0  ...                        88     0\n",
              "4597            0.00                0.0  ...                        14     0\n",
              "4598            0.30                0.0  ...                       118     0\n",
              "4599            0.96                0.0  ...                        78     0\n",
              "4600            0.00                0.0  ...                        40     0\n",
              "\n",
              "[5 rows x 58 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMOevsLfD6Cl",
        "outputId": "eafa3e8c-4949-4c5b-d640-dcd2aa8537f9"
      },
      "source": [
        "# checking the shape of our data\n",
        "email.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4601, 58)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9rHnY1BEHSv"
      },
      "source": [
        "Our data has 4601 observations and 58 columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9h4gH8gEGcI",
        "outputId": "0d6421bb-12ed-40ee-cf8c-2a827926a74c"
      },
      "source": [
        "# checking the dtypes of our columns\n",
        "email.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4601 entries, 0 to 4600\n",
            "Data columns (total 58 columns):\n",
            " #   Column                      Non-Null Count  Dtype  \n",
            "---  ------                      --------------  -----  \n",
            " 0   word_freq_make              4601 non-null   float64\n",
            " 1   word_freq_address           4601 non-null   float64\n",
            " 2   word_freq_all               4601 non-null   float64\n",
            " 3   word_freq_3d                4601 non-null   float64\n",
            " 4   word_freq_our               4601 non-null   float64\n",
            " 5   word_freq_over              4601 non-null   float64\n",
            " 6   word_freq_remove            4601 non-null   float64\n",
            " 7   word_freq_internet          4601 non-null   float64\n",
            " 8   word_freq_order             4601 non-null   float64\n",
            " 9   word_freq_mail              4601 non-null   float64\n",
            " 10  word_freq_receive           4601 non-null   float64\n",
            " 11  word_freq_will              4601 non-null   float64\n",
            " 12  word_freq_people            4601 non-null   float64\n",
            " 13  word_freq_report            4601 non-null   float64\n",
            " 14  word_freq_addresses         4601 non-null   float64\n",
            " 15  word_freq_free              4601 non-null   float64\n",
            " 16  word_freq_business          4601 non-null   float64\n",
            " 17  word_freq_email             4601 non-null   float64\n",
            " 18  word_freq_you               4601 non-null   float64\n",
            " 19  word_freq_credit            4601 non-null   float64\n",
            " 20  word_freq_your              4601 non-null   float64\n",
            " 21  word_freq_font              4601 non-null   float64\n",
            " 22  word_freq_000               4601 non-null   float64\n",
            " 23  word_freq_money             4601 non-null   float64\n",
            " 24  word_freq_hp                4601 non-null   float64\n",
            " 25  word_freq_hpl               4601 non-null   float64\n",
            " 26  word_freq_george            4601 non-null   float64\n",
            " 27  word_freq_650               4601 non-null   float64\n",
            " 28  word_freq_lab               4601 non-null   float64\n",
            " 29  word_freq_labs              4601 non-null   float64\n",
            " 30  word_freq_telnet            4601 non-null   float64\n",
            " 31  word_freq_857               4601 non-null   float64\n",
            " 32  word_freq_data              4601 non-null   float64\n",
            " 33  word_freq_415               4601 non-null   float64\n",
            " 34  word_freq_85                4601 non-null   float64\n",
            " 35  word_freq_technology        4601 non-null   float64\n",
            " 36  word_freq_1999              4601 non-null   float64\n",
            " 37  word_freq_parts             4601 non-null   float64\n",
            " 38  word_freq_pm                4601 non-null   float64\n",
            " 39  word_freq_direct            4601 non-null   float64\n",
            " 40  word_freq_cs                4601 non-null   float64\n",
            " 41  word_freq_meeting           4601 non-null   float64\n",
            " 42  word_freq_original          4601 non-null   float64\n",
            " 43  word_freq_project           4601 non-null   float64\n",
            " 44  word_freq_re                4601 non-null   float64\n",
            " 45  word_freq_edu               4601 non-null   float64\n",
            " 46  word_freq_table             4601 non-null   float64\n",
            " 47  word_freq_conference        4601 non-null   float64\n",
            " 48  char_freq_;                 4601 non-null   float64\n",
            " 49  char_freq_(                 4601 non-null   float64\n",
            " 50  char_freq_[                 4601 non-null   float64\n",
            " 51  char_freq_!                 4601 non-null   float64\n",
            " 52  char_freq_$                 4601 non-null   float64\n",
            " 53  char_freq_#                 4601 non-null   float64\n",
            " 54  capital_run_length_average  4601 non-null   float64\n",
            " 55  capital_run_length_longest  4601 non-null   int64  \n",
            " 56  capital_run_length_total    4601 non-null   int64  \n",
            " 57  spam                        4601 non-null   int64  \n",
            "dtypes: float64(55), int64(3)\n",
            "memory usage: 2.0 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vD9TQDskxYTk"
      },
      "source": [
        "## Tidying the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBi0UAeaEUYz",
        "outputId": "fcd4eaf1-15d0-4f8d-e889-41b80fec718e"
      },
      "source": [
        "# checking for null values\n",
        "email.isnull().sum().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzzK-TPiEci4"
      },
      "source": [
        "There are no null values within our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqV4MdyTEqqu",
        "outputId": "152f9871-45bc-433e-e5e8-7542483e3846"
      },
      "source": [
        "# check for duplicates\n",
        "email.duplicated().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "391"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Cvj4n4WE055"
      },
      "source": [
        "# Dropping our duplicates\n",
        "email.drop_duplicates(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6Tv_cvbF-3Q"
      },
      "source": [
        "- The columns are too numerous, and we must employ reduction techniques to reduce the data dimension.\n",
        "- We'll skip straight to modeling because making charts won't help us analyze the columns.\n",
        "- We will plot the target variable to check its proportion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MvTIo94xdLM"
      },
      "source": [
        "## Exploratory Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "urHlyVImGX-c",
        "outputId": "c96ba9fb-75db-4122-d979-1d5123fd5212"
      },
      "source": [
        "# Plotting the target variable \n",
        "\n",
        "sns.countplot(email.spam)\n",
        "plt.title('Spam vs Non_Spam Emails')\n",
        "plt.xticks([0,1],['Not Spam', 'Spam'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF7TGdQ8802I"
      },
      "source": [
        "~ 2500 of the emails were not spam and ~1700 were spam emails."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isxK3ZMwGz_R",
        "outputId": "bc01c5e5-7a29-49cf-8e0b-6b5ef391f11c"
      },
      "source": [
        "# check proportion of target variable in %\n",
        "email.spam.value_counts(normalize=True)*100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    60.118765\n",
              "1    39.881235\n",
              "Name: spam, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhGQFGugG4_d"
      },
      "source": [
        "60.1% of our emails are normal(**not spam**) and 39.9% are **spam** emails.\n",
        "\n",
        "Our dataset is imbalanced. We will figure out what to do before splitting the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m0RpXNhxh-x"
      },
      "source": [
        "## Implement the solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUZFV742C2dQ"
      },
      "source": [
        "### **Gaussian Naive Bayes Classifier**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdFVplVSECYO"
      },
      "source": [
        "***80/20 SPLIT***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wJL6OY9C5kl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80ada294-1a20-4752-d2bb-0dd880a8a456"
      },
      "source": [
        "# creating a copy of our dataset\n",
        "df = email.copy(deep = True)\n",
        "# getting our independent and dependent variables\n",
        "X = df.drop(columns = ['spam'], axis=1)\n",
        "y = df.spam\n",
        "\n",
        "# Splitting the data to train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.20, random_state=0)\n",
        "# \n",
        "# Training our model\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "clf = GaussianNB()\n",
        "model = clf.fit(X_train, y_train) \n",
        "\n",
        "# Predicting our test predictors\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# evaluating the model\n",
        "from sklearn.metrics import accuracy_score\n",
        "import scipy.stats as stats\n",
        "print(\"The model accuracy is\", accuracy_score(y_test,y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model accuracy is 0.8206650831353919\n",
            "[[357 138]\n",
            " [ 13 334]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.72      0.83       495\n",
            "           1       0.71      0.96      0.82       347\n",
            "\n",
            "    accuracy                           0.82       842\n",
            "   macro avg       0.84      0.84      0.82       842\n",
            "weighted avg       0.86      0.82      0.82       842\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQ_MLRXYEHfp"
      },
      "source": [
        "***70/30 SPLIT***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCcz0KblEN2_",
        "outputId": "cd1208a5-865a-44fb-c2d0-7d493726a92c"
      },
      "source": [
        "# Splitting the data to train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=0)\n",
        "# \n",
        "# Training our model\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "clf = GaussianNB()\n",
        "model = clf.fit(X_train, y_train) \n",
        "\n",
        "# Predicting our test predictors\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# evaluating the model\n",
        "from sklearn.metrics import accuracy_score\n",
        "import scipy.stats as stats\n",
        "print(\"The model accuracy is\", accuracy_score(y_test,y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model accuracy is 0.833729216152019\n",
            "[[541 196]\n",
            " [ 14 512]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.73      0.84       737\n",
            "           1       0.72      0.97      0.83       526\n",
            "\n",
            "    accuracy                           0.83      1263\n",
            "   macro avg       0.85      0.85      0.83      1263\n",
            "weighted avg       0.87      0.83      0.83      1263\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLWoC41NETu8"
      },
      "source": [
        "***60/40 SPLIT***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "um8cuOmgEYLM",
        "outputId": "08707de8-001a-4843-ed25-3b05c6f52f36"
      },
      "source": [
        "# Splitting the data to train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.40, random_state=0)\n",
        "# \n",
        "# Training our model\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "clf = GaussianNB()\n",
        "model = clf.fit(X_train, y_train) \n",
        "\n",
        "# Predicting our test predictors\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# evaluating the model\n",
        "from sklearn.metrics import accuracy_score\n",
        "import scipy.stats as stats\n",
        "print(\"The model accuracy is\", accuracy_score(y_test,y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model accuracy is 0.8319477434679335\n",
            "[[735 259]\n",
            " [ 24 666]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.74      0.84       994\n",
            "           1       0.72      0.97      0.82       690\n",
            "\n",
            "    accuracy                           0.83      1684\n",
            "   macro avg       0.84      0.85      0.83      1684\n",
            "weighted avg       0.87      0.83      0.83      1684\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwAU9fUhEcsv"
      },
      "source": [
        "The Gaussian Naive Bayes model with the 70/30 split performed better with an accuracy score of 83.37%.\n",
        "\n",
        "The 60/40 split yielded an accuracy score of 83.19%. Which was better than the 80/20 split that yielded an accuracy score of 82.07%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjaJ2SETFNWf"
      },
      "source": [
        "### Multinomial Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkxQcAWyFVzA"
      },
      "source": [
        "***80/20 SPLIT***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_97mBxCFMqB",
        "outputId": "7165ff9d-5d3b-46c9-aa2c-aa2e9dd521af"
      },
      "source": [
        "# Splitting the data to train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.20, random_state=0)\n",
        "# \n",
        "# Training our model\n",
        "from sklearn.naive_bayes import MultinomialNB \n",
        "clf = MultinomialNB ()\n",
        "model = clf.fit(X_train, y_train) \n",
        "\n",
        "# Predicting our test predictors\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# evaluating the model\n",
        "from sklearn.metrics import accuracy_score\n",
        "import scipy.stats as stats\n",
        "print(\"The model accuracy is\", accuracy_score(y_test,y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model accuracy is 0.7695961995249406\n",
            "[[415  80]\n",
            " [114 233]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.84      0.81       495\n",
            "           1       0.74      0.67      0.71       347\n",
            "\n",
            "    accuracy                           0.77       842\n",
            "   macro avg       0.76      0.75      0.76       842\n",
            "weighted avg       0.77      0.77      0.77       842\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_ctnGiCFmWi"
      },
      "source": [
        "***70/30 SPLIT***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUjDpFUeFl21",
        "outputId": "03860a03-c8de-4521-e582-ce3d094a5826"
      },
      "source": [
        "# Splitting the data to train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=0)\n",
        "# \n",
        "# Training our model\n",
        "from sklearn.naive_bayes import MultinomialNB \n",
        "clf = MultinomialNB ()\n",
        "model = clf.fit(X_train, y_train) \n",
        "\n",
        "# Predicting our test predictors\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# evaluating the model\n",
        "from sklearn.metrics import accuracy_score\n",
        "import scipy.stats as stats\n",
        "print(\"The model accuracy is\", accuracy_score(y_test,y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model accuracy is 0.782264449722882\n",
            "[[624 113]\n",
            " [162 364]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.85      0.82       737\n",
            "           1       0.76      0.69      0.73       526\n",
            "\n",
            "    accuracy                           0.78      1263\n",
            "   macro avg       0.78      0.77      0.77      1263\n",
            "weighted avg       0.78      0.78      0.78      1263\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pVOH1IYFvWC"
      },
      "source": [
        "***60/40 SPLIT***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "631hztcRFzRj",
        "outputId": "bc50337a-e3e9-4747-b066-c651828c8212"
      },
      "source": [
        "# Splitting the data to train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.40, random_state=0)\n",
        "# \n",
        "# Training our model\n",
        "from sklearn.naive_bayes import MultinomialNB \n",
        "clf = MultinomialNB ()\n",
        "model = clf.fit(X_train, y_train) \n",
        "\n",
        "# Predicting our test predictors\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# evaluating the model\n",
        "from sklearn.metrics import accuracy_score\n",
        "import scipy.stats as stats\n",
        "print(\"The model accuracy is\", accuracy_score(y_test,y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model accuracy is 0.7933491686460807\n",
            "[[838 156]\n",
            " [192 498]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.84      0.83       994\n",
            "           1       0.76      0.72      0.74       690\n",
            "\n",
            "    accuracy                           0.79      1684\n",
            "   macro avg       0.79      0.78      0.78      1684\n",
            "weighted avg       0.79      0.79      0.79      1684\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dz9TcdHIF6hp"
      },
      "source": [
        "The Multinomial Naive bayes classifier with the 60/40 split performed better with an accuracy score of 79.33%. \n",
        "\n",
        "Which was better than the 70/30 which yielded an accuracy score of 78.23% and the 80/20 split which yielded an accuracy score of 76.96%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glfIWbMBG1Bj"
      },
      "source": [
        "The GaussianNB (70/30) performed the best overall (83.37%). We will use this model to tune our parameters and see if we could improve the performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIxfUx2yHYaC"
      },
      "source": [
        "## Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzvF6UKBHZwu",
        "outputId": "fae7da63-a531-4929-c997-df633c15376f"
      },
      "source": [
        "# Let's see the parameters to be hypertuned\n",
        "GaussianNB()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAkn8sXzHhrg",
        "outputId": "10fcdbd4-9c2d-4cec-bfad-54d9e1bfb6a1"
      },
      "source": [
        "# performing gridsearch \n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "\n",
        "np.random.seed(999)\n",
        "\n",
        "nb_classifier = GaussianNB()\n",
        "\n",
        "params_ = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=15, \n",
        "                                    n_repeats=3, \n",
        "                                    random_state=0)\n",
        "\n",
        "gs_ = GridSearchCV(estimator=nb_classifier, \n",
        "                     param_grid=params_, \n",
        "                     cv=cv,\n",
        "                     verbose=1, \n",
        "                     scoring='accuracy')\n",
        "\n",
        "gs_.fit(X_train, y_train)\n",
        "\n",
        "gs_.best_params_\n",
        "print('best parameters:',gs_.best_params_)\n",
        "print('best score:',gs_.best_score_)\n",
        "print('best estimator:',gs_.best_estimator_)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 45 folds for each of 100 candidates, totalling 4500 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "best parameters: {'var_smoothing': 8.111308307896872e-07}\n",
            "best score: 0.8736052409129331\n",
            "best estimator: GaussianNB(priors=None, var_smoothing=8.111308307896872e-07)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 4500 out of 4500 | elapsed:   31.1s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZOfBOnYMUOb",
        "outputId": "cdb2908f-98a2-4753-849d-c2ef5e8f0712"
      },
      "source": [
        "# Let's apply the best params\n",
        "# Splitting the data to train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=0)\n",
        "\n",
        "# Training our model\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "clf = GaussianNB(priors=None, var_smoothing= 8.111308307896872e-07)\n",
        "model = clf.fit(X_train, y_train) \n",
        "\n",
        "# Predicting our test predictors\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# evaluating the model\n",
        "from sklearn.metrics import accuracy_score\n",
        "import scipy.stats as stats\n",
        "print(\"Naive bayes model accuracy(70-30 split) is\", accuracy_score(y_test,y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naive bayes model accuracy(70-30 split) is 0.8788598574821853\n",
            "[[669  68]\n",
            " [ 85 441]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.91      0.90       737\n",
            "           1       0.87      0.84      0.85       526\n",
            "\n",
            "    accuracy                           0.88      1263\n",
            "   macro avg       0.88      0.87      0.87      1263\n",
            "weighted avg       0.88      0.88      0.88      1263\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlP_LzMEM9Cu"
      },
      "source": [
        "The model's accuracy has improved yielding an accuracy score of 87.89% from 83.37%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOOaPi9aNhLV"
      },
      "source": [
        "## Performing LDA "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvPf8ktXNlAe"
      },
      "source": [
        "Let's do an LDA to see whether our accuracy will improve."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBn4wEvaNtRi",
        "outputId": "b586998c-ed00-41f3-aadf-a8ba6ae461c4"
      },
      "source": [
        "# splitting our train and test set \n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30, random_state=0)\n",
        "\n",
        "# Scaling our features.\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# LDA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "lda = LDA(n_components=40)\n",
        "X_train = lda.fit_transform(X_train, y_train)\n",
        "X_test = lda.transform(X_test)\n",
        "\n",
        "# Training our model\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "clf = GaussianNB()\n",
        "model = clf.fit(X_train, y_train) \n",
        "\n",
        "# Predicting \n",
        "y_pred_lda = model.predict(X_test)\n",
        "\n",
        "# evaluating the model\n",
        "from sklearn.metrics import accuracy_score\n",
        "import scipy.stats as stats\n",
        "print(\"The model accuracy is\", accuracy_score(y_test,y_pred_lda))\n",
        "print(confusion_matrix(y_test, y_pred_lda))\n",
        "print(classification_report(y_test, y_pred_lda))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model accuracy is 0.9073634204275535\n",
            "[[693  44]\n",
            " [ 73 453]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.94      0.92       737\n",
            "           1       0.91      0.86      0.89       526\n",
            "\n",
            "    accuracy                           0.91      1263\n",
            "   macro avg       0.91      0.90      0.90      1263\n",
            "weighted avg       0.91      0.91      0.91      1263\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSQubrIkQLVf"
      },
      "source": [
        "The accuracy score yielded was 90.74% which is the best performance overall."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UojsMBBsTCrZ"
      },
      "source": [
        "## Challenge the solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSEid4mGSqpx"
      },
      "source": [
        "# Let's challenge with the SVC model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_aAqq0ySqjl"
      },
      "source": [
        "from sklearn.svm import SVC"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sg8rGzmFTOfJ",
        "outputId": "59f2ddd9-bb71-49e9-dfd8-e7f871169760"
      },
      "source": [
        "# Splitting the data into training and test sets,\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Scaling our features.\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Training our model \n",
        "svm = SVC(C=0.1, gamma=0.001, kernel = 'linear')\n",
        "model = svm.fit(X_train, y_train) \n",
        "\n",
        "# Predicting \n",
        "y_pred_svm = model.predict(X_test)\n",
        "\n",
        "# evaluating the model\n",
        "from sklearn.metrics import accuracy_score\n",
        "import scipy.stats as stats\n",
        "print(\"The model accuracy is\", accuracy_score(y_test,y_pred_svm))\n",
        "print(confusion_matrix(y_test, y_pred_svm))\n",
        "print(classification_report(y_test, y_pred_svm))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model accuracy is 0.9144893111638955\n",
            "[[698  42]\n",
            " [ 66 457]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.94      0.93       740\n",
            "           1       0.92      0.87      0.89       523\n",
            "\n",
            "    accuracy                           0.91      1263\n",
            "   macro avg       0.91      0.91      0.91      1263\n",
            "weighted avg       0.91      0.91      0.91      1263\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcB3hckDUX3z"
      },
      "source": [
        "The Support Vector Model performed well, with an accuracy of 91%, which is comparable to the GaussianNB with LDA."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8M3CKmrUzP4"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQh-NYGoU86_"
      },
      "source": [
        "The Gaussian Naive Bayes classifier combined with LDA produced the best prediction model, with an accuracy score of 90.74 percent. This is the model we will select and employ for future predictions."
      ]
    }
  ]
}